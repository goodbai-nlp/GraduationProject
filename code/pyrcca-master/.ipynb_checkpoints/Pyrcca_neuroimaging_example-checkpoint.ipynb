{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyrcca: regularized kernel canonical correlation analysis in Python and its applications to neuroimaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains analyses and the figures for a Pyrcca analysis on a natural movie fMRI dataset described in the following e-print publication:\n",
    "\n",
    "Bilenko, N.Y. and Gallant, J.L. (2015). Pyrcca: regularized kernel canonical correlation analysis in Python and its applications to neuroimaging. arXiv:1503.01538 [q-bio.QM] http://arxiv.org/abs/1503.01538\n",
    "\n",
    "Download the Pyrcca code from this GitHub repository:\n",
    "https://github.com/gallantlab/pyrcca\n",
    "\n",
    "The dataset used in this notebook is publicly available on on CRCNS:\n",
    "Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., Gallant, J. L. (2014): Gallant Lab Natural Movie 4T fMRI Data. CRCNS.org.\n",
    "http://dx.doi.org/10.6080/K00Z715X\n",
    "\n",
    "Details of the experiments are described in the original publication about this data:\n",
    "Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., and Gallant, J. L. (2011). Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19), 1641-1646.\n",
    "\n",
    "We use Pycortex software to visualize the results. This software is available here:\n",
    "http://pycortex.org\n",
    "\n",
    "To visualize the results in Pycortex, the anatomical files (available with the functional data on CRCNS) must be used to create a surface. We recommend Freesurfer:\n",
    "http://freesurfer.net/\n",
    "\n",
    "Freesurfer surface can be imported into pycortex and aligned with the functional data. This step also allows us to perform voxel selection by choosing only cortical voxels (those that fall within the cortex mask derived in Pycortex from the anatomical surface)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for neuroimaging data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cortex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3a02cddc8703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcortex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mzscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cortex"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import rcca\n",
    "import sys\n",
    "import numpy as np\n",
    "import cortex\n",
    "zscore = lambda d: (d-d.mean(0))/d.std(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from CRCNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this code, download data from CRCNS: http://crcns.org/data-sets/vc/vim-2\n",
    "The following analysis assumes that the data are located in a directory inside the current directory nameded \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "vdata = []\n",
    "numSubjects = 3\n",
    "# subjects is a list of subject names in Pycortex corresponding to the three subjects in the analysis.\n",
    "subjects = ['S1', 'S2', 'S3]\n",
    "# xfms is a list of transform names in Pycortex aligning the functional and anatomical data for each subject.\n",
    "xfms = ['S1_xfm', 'S2_xfm', 'S3_xfm']\n",
    "dataPath =\"./data/VoxelResponses_subject%d.mat\"\n",
    "for subj in range(numSubjects):\n",
    "    # Open data file\n",
    "    f = h5py.File(dataPath % (subj+1),'r')\n",
    "    # Get size of the data\n",
    "    datasize = (int(f[\"ei\"][\"datasize\"].value[2]),int(f[\"ei\"][\"datasize\"].value[1]),int(f[\"ei\"][\"datasize\"].value[0]))\n",
    "    # Get the cortical mask from Pycortex\n",
    "    mask = cortex.db.get_mask(subjects[subj], xfms[subj], type = 'thick')\n",
    "    # Get the training data for the subject\n",
    "    data_subj = np.nan_to_num(zscore(np.nan_to_num(f[\"rt\"].value.T)))\n",
    "    data.append(data_subj.reshape((data_subj.shape[0],)+datasize)[:, mask])\n",
    "    # Get the validation data for the subject\n",
    "    vdata_subj = np.nan_to_num(zscore(np.nan_to_num(f[\"rv\"].value.T)))\n",
    "    vdata.append(vdata_subj.reshape((vdata_subj.shape[0],)+datasize)[:, mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CCA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will consider a range of regularization values betewen 1e-4 and 1e2\n",
    "regs = np.array(np.logspace(-4, 2, 10))\n",
    "\n",
    "\n",
    "# We will consider numbers of components between 3 and 10\n",
    "numCCs = np.arange(3, 11)\n",
    "\n",
    "# Initialize the cca object\n",
    "cca = rcca.CCACrossValidate(numCCs=numCCs, regs=regs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and save the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: this analysis is computationally intensive due to the size of data. Running it in the notebook\n",
    "# would take a considerable amount of time, so we recommend parallelizing it and/or running\n",
    "# it on a computer cluster, and then loading in the results for visualization.\n",
    "\n",
    "# Train the CCA mapping on training data\n",
    "cca.train(data)\n",
    "\n",
    "# Validate the CCA mapping on validation data\n",
    "cca.validate(data)\n",
    "\n",
    "# Compute variance explained for validation responses in each voxel\n",
    "cca.compute_ev(vdata)\n",
    "\n",
    "# Save analysis results\n",
    "cca.save(\"./data/CCA_results.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results for one of the subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlation histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms of correlations between actual and predicted validation responses for all three subjects, as a result of cross-subject prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualization imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Brewer colormaps for visualization\n",
    "from brewer2mpl import qualitative\n",
    "\n",
    "nSubj = len(cca.corrs)\n",
    "nBins = 30\n",
    "bmap = qualitative.Set1[nSubj]\n",
    "f = plt.figure(figsize = (8, 6))\n",
    "ax = f.add_subplot(111)\n",
    "for s in range(nSubj):\n",
    "    # Plot histogram of correlations across all voxels for all three subjects\n",
    "    ax.hist(cca.corrs[s], bins = nBins, color = bmap.mpl_colors[s], histtype=\"stepfilled\", alpha = 0.6)\n",
    "plt.legend(['Subject 1', 'Subject 2', 'Subject 3'], fontsize = 16)\n",
    "ax.set_xlabel('Prediction correlation', fontsize = 20)\n",
    "ax.set_ylabel('Number of voxels', fontsize = 20)\n",
    "ax.set_title(\"Prediction performance across voxels\", fontsize = 20)\n",
    "# Significance threshold at p<0.05 (corrected for multiple comparisons\n",
    "# Significance is calculated using an asymptotic method (see paper text for detail)\n",
    "thresh = 0.0893\n",
    "ax.axvline(x = thresh, ymin = 0, ymax = 7000, linewidth = 2, color = 'k')\n",
    "ax.text(thresh+0.05, 5000, 'p<0.05', fontsize = 16)\n",
    "ax.set_xticklabels(0.1*np.arange(-8, 11, 2), fontsize = 16)\n",
    "ax.set_yticklabels(np.arange(0, 10000, 1000), fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cortical map plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail on visualization via Pycortex, please consult Pycortex documentation at http://pycortex.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map shows the correlations between predicted and actual validation responses as a result of cross-subject prediction for one of the subjects on the cortical map. Correlations that are not significant (p<0.05, corrected for multiple comparisons) are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "from matplotlib import cm\n",
    "from copy import deepcopy\n",
    "subj = 0\n",
    "subjName = \"S1\"\n",
    "subjTransform = \"S1_xfm\"\n",
    "corrs = deepcopy(cca.corrs[subj])\n",
    "# Set all voxels below the signficance threshold to 0\n",
    "corrs[corrs<thresh] = 0\n",
    "_ = cortex.quickflat.make_figure(cortex.Volume(corrs, subjName, subjTransform, cmap = cm.PuBuGn_r, vmin = 0., vmax = 1.), with_curvature = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Canonical component RGB map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canonical weights for all three canonical components estimated by Pyrcca are shown on a flattened cortical map. Each of the canonical components is assigned to one color channel. The first canonical component is represented by the red channel, the second canonical component is represented by green, and the third canonical component is represented by blue. Thus, the color of each voxel reflects its canonical weights for all three canonical components. Canonical weights have been rescaled to span the range from zero to one, and the absolute value of the weights has been taken. This map shows how the BOLD responses of each voxel are described by the three canonical components. The recovered map reveals retinotopic organization of the visual cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rescale = lambda d: 1/(d.max() - d.min())*(d - d.min())\n",
    "\n",
    "_ = cortex.quickflat.make_figure(cortex.VolumeRGB(rescale(np.abs(cca.ws[0].T[0])), rescale(np.abs(cca.ws[0].T[1])), rescale(np.abs(cca.ws[0].T[2])), 'SNfs', 'SNfs4Tnb'), with_curvature = True, with_colorbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual canonical component maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each map shows both the canonical weights for one of the estimated canonical components and the variance of the held-out BOLD responses that was explained by that canonical component. Each voxel is colored according to a two-dimensional colormap. The hue represents the  canonical  weight  of  each  voxel.  Blue  indicates  negative  canonical  weights,  white  indicates  zero weights, and green indicates positive canonical weights. The canonical weights have been rescaled to span the range from -1 to 1. The saturation reflects the variance of each voxelâ€™s held-out BOLD responses that is explained by that canonical component. The saturation ranges from 0% to 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-700fd80f086f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmaxmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_numCC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquickflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcortex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"GreenWhiteBlue_2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmaxmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_curvature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cca' is not defined"
     ]
    }
   ],
   "source": [
    "maxmins = [15, 50, 40]\n",
    "for i in range(cca.best_numCC):\n",
    "    cortex.quickflat.make_figure(cortex.Volume2D(np.nan_to_num(cca.ws[subj].T[i]), np.nan_to_num(cca.ev[subj][i]), subjName, subjTransform, cmap = \"GreenWhiteBlue_2D\", vmin = -maxmins[i], vmax = maxmins[i], vmin2 = 0, vmax2 = 0.75), with_curvature = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
